{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-21T18:28:48.192230Z",
     "start_time": "2024-08-21T18:28:41.399541Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import string\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:28:48.651689Z",
     "start_time": "2024-08-21T18:28:48.193235Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('IMDB Dataset.csv', encoding='utf-8')",
   "id": "ac36d203b0a6daf9",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:28:48.658110Z",
     "start_time": "2024-08-21T18:28:48.652694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextPreprocessor:\n",
    "    def __init__(self, language='english', custom_stopwords=None):\n",
    "        \"\"\"\n",
    "        Initialize the TextPreprocessor class with the specified language for stopwords.\n",
    "        :param language: The language of stopwords to use (default is 'english').\n",
    "        \"\"\"\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "        nltk.download('wordnet')\n",
    "        nltk.download('punkt_tab')\n",
    "\n",
    "        self.stop_words = set(stopwords.words(language))\n",
    "        if custom_stopwords:\n",
    "            self.stop_words.update(custom_stopwords)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.punctuation = set(string.punctuation)\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        \"\"\"\n",
    "        Preprocess the input text by lowering case, removing stopwords, and lemmatizing words.\n",
    "        :param text: The text to preprocess.\n",
    "        :return: A string containing the preprocessed text.\n",
    "        \"\"\"\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "\n",
    "        # Tokenize the text\n",
    "        words = word_tokenize(text)\n",
    "\n",
    "        # Remove stopwords and lemmatize\n",
    "        words = [self.lemmatizer.lemmatize(word) for word in words if\n",
    "                 word.isalpha() and word.lower() not in self.stop_words]\n",
    "\n",
    "        return ' '.join(words)"
   ],
   "id": "3351f7fd6999f9a2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:30:00.148387Z",
     "start_time": "2024-08-21T18:28:48.660120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprocessor = TextPreprocessor(custom_stopwords=['br'])  # Удаление тегов <br>\n",
    "data['processed_review'] = data['review'].apply(preprocessor.preprocess)"
   ],
   "id": "61109499a6231ee4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ilyar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ilyar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ilyar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ilyar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:30:00.162224Z",
     "start_time": "2024-08-21T18:30:00.150396Z"
    }
   },
   "cell_type": "code",
   "source": "data['processed_review'][0]",
   "id": "c50ef0507cf2335e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one reviewer mentioned watching oz episode hooked right exactly happened first thing struck oz brutality unflinching scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use called oz nickname given oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy high agenda em city home many aryan muslim gangsta latino christian italian irish scuffle death stare dodgy dealing shady agreement never far would say main appeal show due fact go show would dare forget pretty picture painted mainstream audience forget charm forget romance oz mess around first episode ever saw struck nasty surreal could say ready watched developed taste oz got accustomed high level graphic violence violence injustice crooked guard sold nickel inmate kill order get away well mannered middle class inmate turned prison bitch due lack street skill prison experience watching oz may become comfortable uncomfortable viewing thats get touch darker side'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:30:00.183759Z",
     "start_time": "2024-08-21T18:30:00.164233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['processed_review'], data['sentiment'], test_size=0.2,\n",
    "                                                    random_state=42)"
   ],
   "id": "457054138f010bd5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-21T18:30:07.506532Z",
     "start_time": "2024-08-21T18:30:00.185773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Преобразование текстовых данных в векторы TF-IDF\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# Обучение модели логистической регрессии\n",
    "clf = LogisticRegression(max_iter=100)\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Преобразование тестовых данных в векторы TF-IDF\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "# Предсказание меток для тестовых данных\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Оценка точности модели\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Вывод отчета о классификации и матрицы ошибок\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ],
   "id": "d1158dcdabadda9a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89      4961\n",
      "    positive       0.88      0.91      0.90      5039\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "[[4359  602]\n",
      " [ 457 4582]]\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
